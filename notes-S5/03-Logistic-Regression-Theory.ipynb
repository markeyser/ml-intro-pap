{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Assignement\n",
    "\n",
    "In this lecture we'll discuss classification problems how to use logistic regression to solve them and how to interpret the results of the logistic regression to wreak confusion matrix.\n",
    "\n",
    "> Sections 4-4.3 of **Introduction to Statistical Learning**\n",
    "\n",
    "If you want to understand the full mathematics behind logistic regression.\n",
    "Go ahead and read sections 4 through 4.3 of introduction to mystical learning by Gary James.\n",
    "\n",
    "## Background\n",
    "\n",
    "- We want to learn about Logistic Regression as method for **Classification**.\n",
    "- Some examples of classification problems:\n",
    "    - Spam versus \"Ham\" emails\n",
    "    - Loan Default (yes/no)\n",
    "    - Disease Diagnosis\n",
    "- Above were all examples of Binary Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far in our studies we've only seen regression problems where we try to predict a continuous value such as the price of a house although the name may be confusing at first.\n",
    "- Logistic Regression allows us to solve classification problems where we're trying to predict discrete categories.\n",
    "- The convention for binary classification is to have two classes 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- However we can't use a normal linear regression model on a binary group. It won't lead to a good fit.\n",
    "\n",
    "For example if we take a look at this plot below we have a Y axis which represents the probability of belonging to a particular group.\n",
    "\n",
    "\n",
    "![](../imgs/logistic1.png)\n",
    "\n",
    "\n",
    "Let's go ahead and imagine that this example plot is trying to predict likelihood of paying back a loan.\n",
    "\n",
    "We'll go ahead and label 0 percent probability as defaulting on their loan meaning they have a zero percent probability of being able to pay back their loan.\n",
    "\n",
    "And at the top we have one or a 100 percent probability as fully paying back their loan. \n",
    "\n",
    "Will go ahead and mark the X axis as some sort of paycheck value. That means if we go ahead and look at this data as your paycheck goes lower you have a closer to zero percent probability that you're going to be able to pay back your loan as your paycheck value gets higher, you then have closer to 100 percent probability of paying back your loan.\n",
    "\n",
    "\n",
    "The reason these yellow dashes are all either on 0 percent or 100 percent is because this is training data. Now if this was trading data and we try to use a linear regression model on it we would get a very bad fit. We would actually end up predicting probabilities below zero percent which doesn't really make any sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead we can transform our linear regression to a logistic regression curve, and you'll notice our logistic regression curve can only go between 0 and 1 and that's going to be the key to understanding classification using a logistic regression curve.\n",
    "\n",
    "![](../imgs/logistic2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Sigmoid Function\n",
    "\n",
    "The sigmoid, also known as logistic function, is going to be the key to understanding using logistic regression to perform a classification.\n",
    "\n",
    "![](../imgs/logistic3.png)\n",
    "\n",
    "\n",
    "The key secret to this function is that it can take in any value and its output is going to be between 0 and 1.\n",
    "\n",
    "\n",
    "We take a look at the equation here on this plot. We have the sigmoid function plotted out on the z axis is going to be the bottom line, usually the x axis there but here without noting it as theta of Z and the formula is theta of Z. So the function of z is equal to 1 over 1 plus E to the power of negative Z.\n",
    "\n",
    "The key thing to notice here is that it doesn't matter what value of Z you put into the logistic function or the sigmoid function. You'll always get a value between 0 and 1.\n",
    "\n",
    "So again if you take a look at this plot it doesn't matter that whatever value you put in for Z the output along the vertical axis is always going to be between 0 and 1. And that's the key the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This means that we can take her linear regression solution and place it into this sigmoid function and that's going to look like this.\n",
    "\n",
    "![](../imgs/logistic4.png)\n",
    "\n",
    "Remember our linear model followed a basic y equals x plus B principle. Here we have a linear model as y equals beta plus Beta 1 times X. If we take that linear model and put it into the sigmoid function we finally are able to transform this linear regression to a logistic model meaning it doesn't matter whatever the value of the linear model output actually is.\n",
    "\n",
    "It's always going to be between 0 and 1 when we place it into the logistic model or the sigmoid function.\n",
    "\n",
    "> If you want more of you on this mathematics make sure to read sections 4 through 4.3 of introduction to Stichel learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But the basic premise of all of this is that this results in a probability from zero to one of belonging in the one class again doesn't matter what we put in on this horizontal access on the vertical axis will always get some sort of probability between 0 and 1.\n",
    "\n",
    "\n",
    "![](../imgs/logistic5.png)\n",
    "\n",
    "\n",
    "That means we can set a cutoff point usually at 0.5 and we'll say if anything below results in 0.5 or below 0.5 that will go to class 0. Anything above belongs to class 1. So we're going to transform that 0.5 probability as a cutoff point. \n",
    "\n",
    "Let's go ahead and do a quick recap overview of what we just discussed.\n",
    "\n",
    "We can use the logistic function to output of values ranging from 0 to 1.\n",
    "Again it doesn't matter what we put along the horizontal axis we get a value from 0 to 1 based off of this probability we will assign a class by putting a cutoff point 0.5 which makes sense because we want to say if the probability is 50 percent or less of belonging to class 1 then we should classify this as Class 0 in our binary classification.\n",
    "If we have a probability of 0.5 or above of belonging to a class 1 we'll go ahead and assign this new point to class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mosdel Evaluation\n",
    "\n",
    "- After you train a logistic regression model on some training data, you will evaulate your model's performance on some test data.\n",
    "\n",
    "- You cn use a confusion matrix to evaluate classification models\n",
    "\n",
    "A **confusion matrix** is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are already known.\n",
    "\n",
    "The confusion matrix itself is actually relatively simple to understand but sometimes the related terminology can be confusing.\n",
    "\n",
    "![](../imgs/logistic6.png)\n",
    "\n",
    "\n",
    "\n",
    "In this case we have a binary classification problem. So in this example we're testing for the presence of a disease where no is a negative test which is false equals zero. Yes ia positive test when True is equal to 1. \n",
    "\n",
    "There are two possible predictive classes Yes, and NO, \n",
    "\n",
    "If we were predicting the presence of a disease for example yes it would mean that they have disease.\n",
    "\n",
    "The classifier made a total of a 165 predictions meaning 165 patients were tested for the presence of the disease.\n",
    "\n",
    "Out of those 165 cases the classifier predicted a yes 110 times and no 55 times.\n",
    "\n",
    "In reality meaning we already have label test data 105 patients in the sample have the disease and 60 patients do not.\n",
    "\n",
    "Now let's go ahead and define the most basic terms the basic terms are the whole number it terms so not rates just hold numbers and those terms are true positives true negatives false positives and false negatives.\n",
    "\n",
    "![](../imgs/logistic7.png)\n",
    "\n",
    "\n",
    "Then we can talk about rates. The first rate we can discuss is **accuracy**.\n",
    "\n",
    "![](../imgs/logistic8.png)\n",
    "\n",
    "What this is actually getting at is overall how often is it correct.\n",
    "\n",
    "A lot of times when you hear reports on studies they'll just tell you the accuracy and the accuracy is calculated by the number of true positives plus the number of true negatives over the total.\n",
    "\n",
    "\n",
    "\n",
    "Then we have the misclassification rate which is answering the question. Overall how often is the model wrong.\n",
    "\n",
    "![](../imgs/logistic9.png)\n",
    "\n",
    "This is going to be calculated by the number of false positives plus a number of false negatives divided\n",
    "\n",
    "by the total.\n",
    "\n",
    "So that's 15 divided by a five.\n",
    "\n",
    "Overall this is 9 percent error rate or misclassification rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
